2023-02-20T09:51:18,156 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-02-20T09:51:18,156 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-02-20T09:51:18,183 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-02-20T09:51:18,183 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-02-20T09:51:18,494 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages
Current directory: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources
Temp directory: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/
Metrics config path: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8192 M
Python executable: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/model_store
Initial Models: helmet_detection.mar
Log dir: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/logs
Metrics dir: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/model_store
Model config: N/A
2023-02-20T09:51:18,494 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages
Current directory: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources
Temp directory: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/
Metrics config path: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8192 M
Python executable: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/model_store
Initial Models: helmet_detection.mar
Log dir: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/logs
Metrics dir: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/model_store
Model config: N/A
2023-02-20T09:51:18,511 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: helmet_detection.mar
2023-02-20T09:51:18,511 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: helmet_detection.mar
2023-02-20T09:51:19,120 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model helmet_detection
2023-02-20T09:51:19,120 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model helmet_detection
2023-02-20T09:51:19,120 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model helmet_detection
2023-02-20T09:51:19,120 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model helmet_detection
2023-02-20T09:51:19,120 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-02-20T09:51:19,120 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-02-20T09:51:19,120 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-02-20T09:51:19,120 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 16
2023-02-20T09:51:19,132 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9007, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,132 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9008, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9004, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9003, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,132 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,132 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9006, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9005, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,132 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9008, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,133 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9010, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9004, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,132 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9007, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,132 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,133 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9012, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,133 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9011, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9003, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,132 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9006, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,133 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9012, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,134 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9009, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,134 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9014, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,134 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9013, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9005, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,131 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,134 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9015, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,133 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9011, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,133 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9010, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,134 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9009, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,134 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9013, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,134 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9014, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,134 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9015, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:51:19,137 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2023-02-20T09:51:19,137 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2023-02-20T09:51:19,234 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-02-20T09:51:19,234 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-02-20T09:51:19,234 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2023-02-20T09:51:19,234 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2023-02-20T09:51:19,236 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-02-20T09:51:19,236 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-02-20T09:51:19,237 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2023-02-20T09:51:19,237 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2023-02-20T09:51:19,238 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-02-20T09:51:19,238 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-02-20T09:51:19,628 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-02-20T09:51:19,628 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-02-20T09:51:19,730 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857879
2023-02-20T09:51:19,731 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:630.1369285583496|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857879
2023-02-20T09:51:19,731 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857879
2023-02-20T09:51:19,732 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857879
2023-02-20T09:51:19,732 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17512.4765625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857879
2023-02-20T09:51:19,732 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13174.23046875|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857879
2023-02-20T09:51:19,733 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857879
2023-02-20T09:51:34,630 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9003
2023-02-20T09:51:34,630 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001
2023-02-20T09:51:34,630 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9014
2023-02-20T09:51:34,630 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9007
2023-02-20T09:51:34,630 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9009
2023-02-20T09:51:34,631 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9010
2023-02-20T09:51:34,630 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9005
2023-02-20T09:51:34,630 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9008
2023-02-20T09:51:34,630 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9013
2023-02-20T09:51:34,630 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000
2023-02-20T09:51:34,631 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9012
2023-02-20T09:51:34,630 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9006
2023-02-20T09:51:34,630 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002
2023-02-20T09:51:34,630 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9004
2023-02-20T09:51:34,631 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9015
2023-02-20T09:51:34,634 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9011
2023-02-20T09:51:34,641 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,641 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,641 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,641 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,641 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,641 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,641 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,641 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,642 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - [PID]91832
2023-02-20T09:51:34,642 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - [PID]91837
2023-02-20T09:51:34,642 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - [PID]91827
2023-02-20T09:51:34,642 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - [PID]91826
2023-02-20T09:51:34,642 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - [PID]91838
2023-02-20T09:51:34,642 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,642 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,643 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,642 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,643 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,642 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,642 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,642 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,642 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,642 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - [PID]91834
2023-02-20T09:51:34,642 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,644 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - [PID]91835
2023-02-20T09:51:34,643 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,644 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - [PID]91830
2023-02-20T09:51:34,644 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,644 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,642 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,644 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,644 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,645 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,644 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,645 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - [PID]91828
2023-02-20T09:51:34,642 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,645 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,644 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,645 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,643 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,642 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,645 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,644 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,644 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,645 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,643 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,645 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - [PID]91833
2023-02-20T09:51:34,645 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,642 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,645 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,645 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,645 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,645 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,644 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - [PID]91829
2023-02-20T09:51:34,645 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,642 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,643 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,645 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,645 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,646 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,645 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,645 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,646 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,646 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,646 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - [PID]91831
2023-02-20T09:51:34,646 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,646 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,646 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,646 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,646 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,646 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,646 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,647 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - [PID]91841
2023-02-20T09:51:34,647 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,647 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,647 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,647 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,647 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,650 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002
2023-02-20T09:51:34,650 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9008
2023-02-20T09:51:34,650 [INFO ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9012
2023-02-20T09:51:34,650 [INFO ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9014
2023-02-20T09:51:34,650 [INFO ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9013
2023-02-20T09:51:34,650 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9008
2023-02-20T09:51:34,650 [INFO ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9009
2023-02-20T09:51:34,650 [INFO ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9003
2023-02-20T09:51:34,650 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001
2023-02-20T09:51:34,651 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,650 [INFO ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9003
2023-02-20T09:51:34,650 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001
2023-02-20T09:51:34,650 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002
2023-02-20T09:51:34,650 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000
2023-02-20T09:51:34,650 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9004
2023-02-20T09:51:34,650 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,650 [INFO ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9013
2023-02-20T09:51:34,650 [INFO ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9005
2023-02-20T09:51:34,650 [INFO ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9014
2023-02-20T09:51:34,650 [INFO ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9007
2023-02-20T09:51:34,650 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9004
2023-02-20T09:51:34,650 [INFO ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9009
2023-02-20T09:51:34,651 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:51:34,650 [INFO ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9005
2023-02-20T09:51:34,651 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - [PID]91839
2023-02-20T09:51:34,650 [INFO ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9012
2023-02-20T09:51:34,650 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000
2023-02-20T09:51:34,651 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - [PID]91836
2023-02-20T09:51:34,651 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,650 [INFO ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9006
2023-02-20T09:51:34,651 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - [PID]91840
2023-02-20T09:51:34,650 [INFO ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9007
2023-02-20T09:51:34,652 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,650 [INFO ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9006
2023-02-20T09:51:34,652 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,652 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,652 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,652 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,652 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,652 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,652 [INFO ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9015
2023-02-20T09:51:34,652 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:51:34,652 [INFO ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9011
2023-02-20T09:51:34,652 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:51:34,652 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,653 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9010
2023-02-20T09:51:34,652 [INFO ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9011
2023-02-20T09:51:34,653 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:51:34,652 [INFO ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9015
2023-02-20T09:51:34,653 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9010
2023-02-20T09:51:34,665 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9013.
2023-02-20T09:51:34,665 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9014.
2023-02-20T09:51:34,666 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000.
2023-02-20T09:51:34,665 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9015.
2023-02-20T09:51:34,665 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9005.
2023-02-20T09:51:34,665 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9004.
2023-02-20T09:51:34,665 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9003.
2023-02-20T09:51:34,665 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002.
2023-02-20T09:51:34,666 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9009.
2023-02-20T09:51:34,665 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9011.
2023-02-20T09:51:34,666 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9006.
2023-02-20T09:51:34,666 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9012.
2023-02-20T09:51:34,666 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001.
2023-02-20T09:51:34,666 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9008.
2023-02-20T09:51:34,666 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9007.
2023-02-20T09:51:34,665 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9010.
2023-02-20T09:51:34,669 [INFO ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,669 [INFO ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857894669
2023-02-20T09:51:34,713 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,714 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,720 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,720 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,722 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,722 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,722 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,722 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,722 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,723 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,723 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,723 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,723 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,723 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,723 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:34,723 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:51:44,750 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,751 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,751 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,751 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,751 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,751 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,751 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,751 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,752 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,752 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,752 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,753 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,753 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,753 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,753 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,753 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,753 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,754 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,754 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,754 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,754 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,754 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,754 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,754 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,754 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,754 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,754 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,754 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,755 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,755 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,755 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,755 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,755 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,755 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,755 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,755 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,755 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,755 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,755 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,755 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,755 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,756 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,756 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,756 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,757 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,757 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,757 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,757 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,757 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,757 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,757 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,757 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,757 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,757 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,757 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,757 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,758 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,758 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,758 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,758 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,759 [INFO ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10036
2023-02-20T09:51:44,759 [INFO ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10036
2023-02-20T09:51:44,759 [INFO ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10036
2023-02-20T09:51:44,759 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10038
2023-02-20T09:51:44,759 [INFO ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10036
2023-02-20T09:51:44,759 [INFO ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,759 [INFO ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,759 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10036
2023-02-20T09:51:44,759 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10036
2023-02-20T09:51:44,759 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10038
2023-02-20T09:51:44,759 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10038
2023-02-20T09:51:44,759 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10046
2023-02-20T09:51:44,759 [INFO ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,759 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10046
2023-02-20T09:51:44,759 [INFO ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,759 [INFO ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10036
2023-02-20T09:51:44,759 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,759 [INFO ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10045
2023-02-20T09:51:44,759 [INFO ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10036
2023-02-20T09:51:44,759 [INFO ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10039
2023-02-20T09:51:44,760 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,759 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10038
2023-02-20T09:51:44,759 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10038
2023-02-20T09:51:44,760 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,759 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10038
2023-02-20T09:51:44,760 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,759 [INFO ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,759 [INFO ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10045
2023-02-20T09:51:44,760 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,759 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,760 [INFO ] W-9010-helmet_detection_0.1 TS_METRICS - W-9010-helmet_detection_0.1.ms:25629|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,760 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,759 [INFO ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,759 [INFO ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,760 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,759 [INFO ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10037
2023-02-20T09:51:44,760 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [INFO ] W-9004-helmet_detection_0.1 TS_METRICS - W-9004-helmet_detection_0.1.ms:25631|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,760 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [INFO ] W-9010-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:53|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,760 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [INFO ] W-9008-helmet_detection_0.1 TS_METRICS - W-9008-helmet_detection_0.1.ms:25630|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,759 [INFO ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10039
2023-02-20T09:51:44,760 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [INFO ] W-9008-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:54|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,760 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [INFO ] W-9004-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:55|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - W-9002-helmet_detection_0.1.ms:25633|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,760 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [INFO ] W-9011-helmet_detection_0.1 TS_METRICS - W-9011-helmet_detection_0.1.ms:25629|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9007-helmet_detection_0.1 TS_METRICS - W-9007-helmet_detection_0.1.ms:25631|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9015-helmet_detection_0.1 TS_METRICS - W-9015-helmet_detection_0.1.ms:25628|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9007-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:56|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,760 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [INFO ] W-9015-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:55|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - W-9000-helmet_detection_0.1.ms:25635|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:54|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,760 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:46|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9014-helmet_detection_0.1 TS_METRICS - W-9014-helmet_detection_0.1.ms:25628|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - W-9001-helmet_detection_0.1.ms:25633|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9014-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:55|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9006-helmet_detection_0.1 TS_METRICS - W-9006-helmet_detection_0.1.ms:25632|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9013-helmet_detection_0.1 TS_METRICS - W-9013-helmet_detection_0.1.ms:25629|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9011-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:55|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,762 [INFO ] W-9006-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:56|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:56|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,761 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,762 [INFO ] W-9013-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:56|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,760 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,761 [INFO ] W-9003-helmet_detection_0.1 TS_METRICS - W-9003-helmet_detection_0.1.ms:25633|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,762 [INFO ] W-9003-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:57|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,762 [INFO ] W-9005-helmet_detection_0.1 TS_METRICS - W-9005-helmet_detection_0.1.ms:25633|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,762 [INFO ] W-9009-helmet_detection_0.1 TS_METRICS - W-9009-helmet_detection_0.1.ms:25632|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,762 [INFO ] W-9005-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:54|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,762 [INFO ] W-9009-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:48|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,767 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/767ef9a48a04459dba0d11a4240b0612/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:51:44,767 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:51:44,768 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:51:44,768 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:51:44,768 [INFO ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10048
2023-02-20T09:51:44,768 [INFO ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10048
2023-02-20T09:51:44,768 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,768 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:51:44,768 [INFO ] W-9012-helmet_detection_0.1 TS_METRICS - W-9012-helmet_detection_0.1.ms:25636|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:51:44,768 [INFO ] W-9012-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:51|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857904
2023-02-20T09:52:01,653 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857921653
2023-02-20T09:52:01,653 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857921653
2023-02-20T09:52:01,656 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676857921
2023-02-20T09:52:02,117 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:461.37|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:d71b83f7-5aa3-4ad6-a96f-8f82d996d8f5,timestamp:1676857922
2023-02-20T09:52:02,118 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:462.36|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:d71b83f7-5aa3-4ad6-a96f-8f82d996d8f5,timestamp:1676857922
2023-02-20T09:52:02,119 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 464
2023-02-20T09:52:02,119 [INFO ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 464
2023-02-20T09:52:02,119 [INFO ] W-9010-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51089 "PUT /predictions/helmet_detection HTTP/1.1" 200 471
2023-02-20T09:52:02,120 [INFO ] W-9010-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:52:02,120 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 135233, Backend time ns: 466459351
2023-02-20T09:52:02,120 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 135233, Backend time ns: 466459351
2023-02-20T09:52:02,120 [INFO ] W-9010-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857922
2023-02-20T09:52:02,120 [INFO ] W-9010-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857922
2023-02-20T09:52:18,073 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857938073
2023-02-20T09:52:18,073 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857938073
2023-02-20T09:52:18,075 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676857938
2023-02-20T09:52:18,525 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:449.55|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:438dd330-89da-4e86-849b-1692f0c0d321,timestamp:1676857938
2023-02-20T09:52:18,525 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 450
2023-02-20T09:52:18,525 [INFO ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 450
2023-02-20T09:52:18,525 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:450.01|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:438dd330-89da-4e86-849b-1692f0c0d321,timestamp:1676857938
2023-02-20T09:52:18,526 [INFO ] W-9008-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51096 "PUT /predictions/helmet_detection HTTP/1.1" 200 453
2023-02-20T09:52:18,526 [INFO ] W-9008-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:52:18,526 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 108907, Backend time ns: 452504402
2023-02-20T09:52:18,526 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 108907, Backend time ns: 452504402
2023-02-20T09:52:18,526 [INFO ] W-9008-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857938
2023-02-20T09:52:18,526 [INFO ] W-9008-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857938
2023-02-20T09:52:19,712 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857939
2023-02-20T09:52:19,712 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:630.3343467712402|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857939
2023-02-20T09:52:19,712 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857939
2023-02-20T09:52:19,713 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857939
2023-02-20T09:52:19,713 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:15723.62890625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857939
2023-02-20T09:52:19,713 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:14963.66015625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857939
2023-02-20T09:52:19,713 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:52.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857939
2023-02-20T09:52:47,955 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857967955
2023-02-20T09:52:47,955 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676857967955
2023-02-20T09:52:47,956 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676857967
2023-02-20T09:52:48,404 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:447.38|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:86d08f3f-78ed-42f9-afdf-e2eff7b04026,timestamp:1676857968
2023-02-20T09:52:48,404 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:448.15|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:86d08f3f-78ed-42f9-afdf-e2eff7b04026,timestamp:1676857968
2023-02-20T09:52:48,404 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 448
2023-02-20T09:52:48,404 [INFO ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 448
2023-02-20T09:52:48,405 [INFO ] W-9004-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51104 "PUT /predictions/helmet_detection HTTP/1.1" 200 451
2023-02-20T09:52:48,405 [INFO ] W-9004-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:52:48,405 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 68630, Backend time ns: 450013315
2023-02-20T09:52:48,405 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 68630, Backend time ns: 450013315
2023-02-20T09:52:48,405 [INFO ] W-9004-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857968
2023-02-20T09:52:48,405 [INFO ] W-9004-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857968
2023-02-20T09:53:15,103 [DEBUG] KQueueEventLoopGroup-3-4 org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model helmet_detection
2023-02-20T09:53:15,103 [DEBUG] KQueueEventLoopGroup-3-4 org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model helmet_detection
2023-02-20T09:53:15,106 [INFO ] KQueueEventLoopGroup-3-4 ACCESS_LOG - /127.0.0.1:51111 "POST /models?url=./model_store/helmet_detection.mar&model_name=helmet_detection HTTP/1.1" 409 487
2023-02-20T09:53:15,106 [INFO ] KQueueEventLoopGroup-3-4 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:53:19,719 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857999
2023-02-20T09:53:19,719 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:630.3073310852051|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857999
2023-02-20T09:53:19,719 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857999
2023-02-20T09:53:19,719 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857999
2023-02-20T09:53:19,719 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:15672.74609375|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857999
2023-02-20T09:53:19,719 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:15014.4375|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857999
2023-02-20T09:53:19,719 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:52.2|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857999
2023-02-20T09:53:23,248 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 3
2023-02-20T09:53:23,248 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 3
2023-02-20T09:53:23,248 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,248 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,249 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-helmet_detection_0.1-stderr
2023-02-20T09:53:23,249 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-helmet_detection_0.1-stderr
2023-02-20T09:53:23,249 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-helmet_detection_0.1-stdout
2023-02-20T09:53:23,249 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-helmet_detection_0.1-stdout
2023-02-20T09:53:23,249 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,249 [INFO ] W-9015-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,249 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,249 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,249 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,249 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,249 [INFO ] W-9015-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-helmet_detection_0.1-stdout
2023-02-20T09:53:23,249 [INFO ] W-9015-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-helmet_detection_0.1-stdout
2023-02-20T09:53:23,249 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,250 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,250 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9015-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,250 [WARN ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-helmet_detection_0.1-stderr
2023-02-20T09:53:23,250 [INFO ] W-9015-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-helmet_detection_0.1-stderr
2023-02-20T09:53:23,250 [WARN ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-helmet_detection_0.1-stderr
2023-02-20T09:53:23,251 [WARN ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-helmet_detection_0.1-stdout
2023-02-20T09:53:23,250 [INFO ] W-9015-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-helmet_detection_0.1-stderr
2023-02-20T09:53:23,251 [WARN ] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-helmet_detection_0.1-stdout
2023-02-20T09:53:23,251 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,251 [DEBUG] W-9015-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,257 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,257 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,257 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-helmet_detection_0.1-stderr
2023-02-20T09:53:23,257 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-helmet_detection_0.1-stderr
2023-02-20T09:53:23,257 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-helmet_detection_0.1-stdout
2023-02-20T09:53:23,257 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-helmet_detection_0.1-stdout
2023-02-20T09:53:23,257 [INFO ] W-9014-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,257 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,257 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,258 [INFO ] W-9014-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-helmet_detection_0.1-stdout
2023-02-20T09:53:23,257 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,258 [INFO ] W-9014-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-helmet_detection_0.1-stdout
2023-02-20T09:53:23,258 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,257 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,258 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,258 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,258 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9014-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,258 [WARN ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-helmet_detection_0.1-stderr
2023-02-20T09:53:23,258 [WARN ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-helmet_detection_0.1-stderr
2023-02-20T09:53:23,258 [INFO ] W-9014-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-helmet_detection_0.1-stderr
2023-02-20T09:53:23,258 [WARN ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-helmet_detection_0.1-stdout
2023-02-20T09:53:23,258 [WARN ] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-helmet_detection_0.1-stdout
2023-02-20T09:53:23,258 [INFO ] W-9014-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-helmet_detection_0.1-stderr
2023-02-20T09:53:23,259 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,259 [DEBUG] W-9014-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,264 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,264 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,264 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-helmet_detection_0.1-stderr
2023-02-20T09:53:23,264 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-helmet_detection_0.1-stderr
2023-02-20T09:53:23,264 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-helmet_detection_0.1-stdout
2023-02-20T09:53:23,264 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-helmet_detection_0.1-stdout
2023-02-20T09:53:23,264 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,264 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,264 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,264 [INFO ] W-9013-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,264 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,264 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,264 [INFO ] W-9013-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-helmet_detection_0.1-stdout
2023-02-20T09:53:23,264 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,264 [INFO ] W-9013-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-helmet_detection_0.1-stdout
2023-02-20T09:53:23,265 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,265 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9013-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,265 [WARN ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-helmet_detection_0.1-stderr
2023-02-20T09:53:23,265 [INFO ] W-9013-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-helmet_detection_0.1-stderr
2023-02-20T09:53:23,265 [WARN ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-helmet_detection_0.1-stderr
2023-02-20T09:53:23,265 [WARN ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-helmet_detection_0.1-stdout
2023-02-20T09:53:23,265 [WARN ] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-helmet_detection_0.1-stdout
2023-02-20T09:53:23,265 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,265 [INFO ] W-9013-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-helmet_detection_0.1-stderr
2023-02-20T09:53:23,265 [DEBUG] W-9013-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,270 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,270 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,270 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-helmet_detection_0.1-stderr
2023-02-20T09:53:23,270 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-helmet_detection_0.1-stderr
2023-02-20T09:53:23,270 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-helmet_detection_0.1-stdout
2023-02-20T09:53:23,270 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-helmet_detection_0.1-stdout
2023-02-20T09:53:23,270 [INFO ] W-9012-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,270 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,270 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,270 [INFO ] W-9012-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-helmet_detection_0.1-stdout
2023-02-20T09:53:23,270 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,270 [INFO ] W-9012-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-helmet_detection_0.1-stdout
2023-02-20T09:53:23,270 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,270 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,270 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,271 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,271 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9012-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,271 [WARN ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-helmet_detection_0.1-stderr
2023-02-20T09:53:23,271 [INFO ] W-9012-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-helmet_detection_0.1-stderr
2023-02-20T09:53:23,271 [WARN ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-helmet_detection_0.1-stderr
2023-02-20T09:53:23,271 [WARN ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-helmet_detection_0.1-stdout
2023-02-20T09:53:23,271 [INFO ] W-9012-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-helmet_detection_0.1-stderr
2023-02-20T09:53:23,271 [WARN ] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-helmet_detection_0.1-stdout
2023-02-20T09:53:23,271 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,271 [DEBUG] W-9012-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,277 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,277 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,277 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-helmet_detection_0.1-stderr
2023-02-20T09:53:23,277 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-helmet_detection_0.1-stderr
2023-02-20T09:53:23,277 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-helmet_detection_0.1-stdout
2023-02-20T09:53:23,277 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-helmet_detection_0.1-stdout
2023-02-20T09:53:23,277 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,277 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,277 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,277 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,277 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,278 [INFO ] W-9011-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,278 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,278 [INFO ] W-9011-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-helmet_detection_0.1-stdout
2023-02-20T09:53:23,278 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9011-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,278 [INFO ] W-9011-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-helmet_detection_0.1-stdout
2023-02-20T09:53:23,277 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,279 [INFO ] W-9011-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-helmet_detection_0.1-stderr
2023-02-20T09:53:23,279 [WARN ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-helmet_detection_0.1-stderr
2023-02-20T09:53:23,279 [WARN ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-helmet_detection_0.1-stderr
2023-02-20T09:53:23,279 [INFO ] W-9011-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-helmet_detection_0.1-stderr
2023-02-20T09:53:23,279 [WARN ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-helmet_detection_0.1-stdout
2023-02-20T09:53:23,279 [WARN ] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-helmet_detection_0.1-stdout
2023-02-20T09:53:23,279 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,279 [DEBUG] W-9011-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,284 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,284 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,285 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-helmet_detection_0.1-stderr
2023-02-20T09:53:23,285 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-helmet_detection_0.1-stderr
2023-02-20T09:53:23,285 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-helmet_detection_0.1-stdout
2023-02-20T09:53:23,285 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-helmet_detection_0.1-stdout
2023-02-20T09:53:23,285 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,285 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,285 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,285 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,285 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,285 [INFO ] W-9010-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,285 [INFO ] W-9010-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-helmet_detection_0.1-stdout
2023-02-20T09:53:23,285 [INFO ] W-9010-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-helmet_detection_0.1-stdout
2023-02-20T09:53:23,285 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,285 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,285 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9010-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,286 [WARN ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-helmet_detection_0.1-stderr
2023-02-20T09:53:23,286 [INFO ] W-9010-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-helmet_detection_0.1-stderr
2023-02-20T09:53:23,286 [WARN ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-helmet_detection_0.1-stderr
2023-02-20T09:53:23,286 [WARN ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-helmet_detection_0.1-stdout
2023-02-20T09:53:23,286 [WARN ] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-helmet_detection_0.1-stdout
2023-02-20T09:53:23,286 [INFO ] W-9010-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-helmet_detection_0.1-stderr
2023-02-20T09:53:23,286 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,286 [DEBUG] W-9010-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,292 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,292 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,292 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-helmet_detection_0.1-stderr
2023-02-20T09:53:23,292 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-helmet_detection_0.1-stderr
2023-02-20T09:53:23,292 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-helmet_detection_0.1-stdout
2023-02-20T09:53:23,292 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-helmet_detection_0.1-stdout
2023-02-20T09:53:23,292 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,292 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,292 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,292 [INFO ] W-9009-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,292 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,293 [INFO ] W-9009-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-helmet_detection_0.1-stdout
2023-02-20T09:53:23,292 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,292 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,293 [INFO ] W-9009-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-helmet_detection_0.1-stdout
2023-02-20T09:53:23,293 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,293 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9009-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,294 [WARN ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-helmet_detection_0.1-stderr
2023-02-20T09:53:23,294 [INFO ] W-9009-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-helmet_detection_0.1-stderr
2023-02-20T09:53:23,294 [WARN ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-helmet_detection_0.1-stderr
2023-02-20T09:53:23,294 [WARN ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-helmet_detection_0.1-stdout
2023-02-20T09:53:23,294 [INFO ] W-9009-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-helmet_detection_0.1-stderr
2023-02-20T09:53:23,294 [WARN ] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-helmet_detection_0.1-stdout
2023-02-20T09:53:23,294 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,294 [DEBUG] W-9009-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,299 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,299 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,299 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-helmet_detection_0.1-stderr
2023-02-20T09:53:23,299 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-helmet_detection_0.1-stderr
2023-02-20T09:53:23,299 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-helmet_detection_0.1-stdout
2023-02-20T09:53:23,299 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-helmet_detection_0.1-stdout
2023-02-20T09:53:23,299 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,299 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,299 [INFO ] W-9008-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,299 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,299 [INFO ] W-9008-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-helmet_detection_0.1-stdout
2023-02-20T09:53:23,299 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,299 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,299 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,299 [INFO ] W-9008-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-helmet_detection_0.1-stdout
2023-02-20T09:53:23,300 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,300 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9008-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,300 [WARN ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-helmet_detection_0.1-stderr
2023-02-20T09:53:23,300 [INFO ] W-9008-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-helmet_detection_0.1-stderr
2023-02-20T09:53:23,300 [WARN ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-helmet_detection_0.1-stderr
2023-02-20T09:53:23,300 [WARN ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-helmet_detection_0.1-stdout
2023-02-20T09:53:23,300 [WARN ] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-helmet_detection_0.1-stdout
2023-02-20T09:53:23,301 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,300 [INFO ] W-9008-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-helmet_detection_0.1-stderr
2023-02-20T09:53:23,301 [DEBUG] W-9008-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,306 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,306 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,306 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-helmet_detection_0.1-stderr
2023-02-20T09:53:23,306 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-helmet_detection_0.1-stderr
2023-02-20T09:53:23,306 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-helmet_detection_0.1-stdout
2023-02-20T09:53:23,306 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-helmet_detection_0.1-stdout
2023-02-20T09:53:23,306 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,306 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,306 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,306 [INFO ] W-9007-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,306 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,307 [INFO ] W-9007-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-helmet_detection_0.1-stdout
2023-02-20T09:53:23,306 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,306 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,307 [INFO ] W-9007-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-helmet_detection_0.1-stdout
2023-02-20T09:53:23,307 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,307 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9007-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,308 [WARN ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-helmet_detection_0.1-stderr
2023-02-20T09:53:23,308 [INFO ] W-9007-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-helmet_detection_0.1-stderr
2023-02-20T09:53:23,308 [WARN ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-helmet_detection_0.1-stderr
2023-02-20T09:53:23,308 [WARN ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-helmet_detection_0.1-stdout
2023-02-20T09:53:23,308 [WARN ] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-helmet_detection_0.1-stdout
2023-02-20T09:53:23,308 [INFO ] W-9007-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-helmet_detection_0.1-stderr
2023-02-20T09:53:23,308 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,308 [DEBUG] W-9007-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,313 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,313 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,313 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-helmet_detection_0.1-stderr
2023-02-20T09:53:23,313 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-helmet_detection_0.1-stderr
2023-02-20T09:53:23,313 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-helmet_detection_0.1-stdout
2023-02-20T09:53:23,313 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-helmet_detection_0.1-stdout
2023-02-20T09:53:23,313 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,313 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,313 [INFO ] W-9006-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,313 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,313 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,313 [INFO ] W-9006-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-helmet_detection_0.1-stdout
2023-02-20T09:53:23,313 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,313 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,313 [INFO ] W-9006-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-helmet_detection_0.1-stdout
2023-02-20T09:53:23,313 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9006-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,313 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,314 [INFO ] W-9006-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-helmet_detection_0.1-stderr
2023-02-20T09:53:23,314 [WARN ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-helmet_detection_0.1-stderr
2023-02-20T09:53:23,314 [INFO ] W-9006-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-helmet_detection_0.1-stderr
2023-02-20T09:53:23,314 [WARN ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-helmet_detection_0.1-stderr
2023-02-20T09:53:23,315 [WARN ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-helmet_detection_0.1-stdout
2023-02-20T09:53:23,315 [WARN ] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-helmet_detection_0.1-stdout
2023-02-20T09:53:23,315 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,315 [DEBUG] W-9006-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,320 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,320 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,320 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-helmet_detection_0.1-stderr
2023-02-20T09:53:23,320 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-helmet_detection_0.1-stderr
2023-02-20T09:53:23,320 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-helmet_detection_0.1-stdout
2023-02-20T09:53:23,320 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-helmet_detection_0.1-stdout
2023-02-20T09:53:23,320 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,320 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,320 [INFO ] W-9005-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,320 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,320 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,320 [INFO ] W-9005-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-helmet_detection_0.1-stdout
2023-02-20T09:53:23,320 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,320 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,320 [INFO ] W-9005-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-helmet_detection_0.1-stdout
2023-02-20T09:53:23,321 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,321 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9005-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,321 [INFO ] W-9005-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-helmet_detection_0.1-stderr
2023-02-20T09:53:23,321 [WARN ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-helmet_detection_0.1-stderr
2023-02-20T09:53:23,321 [INFO ] W-9005-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-helmet_detection_0.1-stderr
2023-02-20T09:53:23,321 [WARN ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-helmet_detection_0.1-stderr
2023-02-20T09:53:23,321 [WARN ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-helmet_detection_0.1-stdout
2023-02-20T09:53:23,321 [WARN ] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-helmet_detection_0.1-stdout
2023-02-20T09:53:23,321 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,321 [DEBUG] W-9005-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,329 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,329 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,329 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-helmet_detection_0.1-stderr
2023-02-20T09:53:23,329 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-helmet_detection_0.1-stderr
2023-02-20T09:53:23,329 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-helmet_detection_0.1-stdout
2023-02-20T09:53:23,329 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-helmet_detection_0.1-stdout
2023-02-20T09:53:23,329 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,329 [INFO ] W-9004-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,329 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,329 [INFO ] W-9004-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-helmet_detection_0.1-stdout
2023-02-20T09:53:23,329 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,329 [INFO ] W-9004-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-helmet_detection_0.1-stdout
2023-02-20T09:53:23,329 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,329 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,329 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,329 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,329 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9004-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,330 [INFO ] W-9004-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-helmet_detection_0.1-stderr
2023-02-20T09:53:23,330 [WARN ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-helmet_detection_0.1-stderr
2023-02-20T09:53:23,330 [WARN ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-helmet_detection_0.1-stderr
2023-02-20T09:53:23,330 [INFO ] W-9004-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-helmet_detection_0.1-stderr
2023-02-20T09:53:23,330 [WARN ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-helmet_detection_0.1-stdout
2023-02-20T09:53:23,330 [WARN ] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-helmet_detection_0.1-stdout
2023-02-20T09:53:23,330 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,330 [DEBUG] W-9004-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,335 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,335 [DEBUG] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_0.1 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-02-20T09:53:23,335 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-helmet_detection_0.1-stderr
2023-02-20T09:53:23,335 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-helmet_detection_0.1-stderr
2023-02-20T09:53:23,335 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-helmet_detection_0.1-stdout
2023-02-20T09:53:23,335 [WARN ] KQueueEventLoopGroup-3-5 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-helmet_detection_0.1-stdout
2023-02-20T09:53:23,335 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,335 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,335 [INFO ] W-9003-helmet_detection_0.1-stdout MODEL_LOG - Frontend disconnected.
2023-02-20T09:53:23,335 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_SCALED_DOWN
2023-02-20T09:53:23,335 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-02-20T09:53:23,336 [INFO ] W-9003-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-helmet_detection_0.1-stdout
2023-02-20T09:53:23,336 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,336 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-02-20T09:53:23,336 [INFO ] W-9003-helmet_detection_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-helmet_detection_0.1-stdout
2023-02-20T09:53:23,336 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,336 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9003-helmet_detection_0.1 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-02-20T09:53:23,336 [WARN ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-helmet_detection_0.1-stderr
2023-02-20T09:53:23,336 [WARN ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-helmet_detection_0.1-stderr
2023-02-20T09:53:23,336 [INFO ] W-9003-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-helmet_detection_0.1-stderr
2023-02-20T09:53:23,336 [WARN ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-helmet_detection_0.1-stdout
2023-02-20T09:53:23,336 [WARN ] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-helmet_detection_0.1-stdout
2023-02-20T09:53:23,336 [INFO ] W-9003-helmet_detection_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-helmet_detection_0.1-stderr
2023-02-20T09:53:23,337 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,337 [DEBUG] W-9003-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-02-20T09:53:23,345 [INFO ] KQueueEventLoopGroup-3-5 ACCESS_LOG - /127.0.0.1:51112 "PUT /models/helmet_detection?min_worker=3 HTTP/1.1" 202 97
2023-02-20T09:53:23,345 [INFO ] KQueueEventLoopGroup-3-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:53:30,458 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858010458
2023-02-20T09:53:30,458 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858010458
2023-02-20T09:53:30,459 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858010
2023-02-20T09:53:30,904 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:444.48|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:70d00704-60fb-498e-9bd1-771f3aa6a03a,timestamp:1676858010
2023-02-20T09:53:30,904 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:445.36|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:70d00704-60fb-498e-9bd1-771f3aa6a03a,timestamp:1676858010
2023-02-20T09:53:30,904 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 445
2023-02-20T09:53:30,904 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 445
2023-02-20T09:53:30,905 [INFO ] W-9002-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51114 "PUT /predictions/helmet_detection HTTP/1.1" 200 448
2023-02-20T09:53:30,905 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:53:30,905 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 72045, Backend time ns: 447137253
2023-02-20T09:53:30,905 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 72045, Backend time ns: 447137253
2023-02-20T09:53:30,905 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858010
2023-02-20T09:53:30,905 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858010
2023-02-20T09:53:51,527 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858031527
2023-02-20T09:53:51,527 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858031527
2023-02-20T09:53:51,528 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858031
2023-02-20T09:53:51,966 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:437.16|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:2d67f515-974b-450d-87a5-a9322055f29c,timestamp:1676858031
2023-02-20T09:53:51,966 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:437.62|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:2d67f515-974b-450d-87a5-a9322055f29c,timestamp:1676858031
2023-02-20T09:53:51,966 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 438
2023-02-20T09:53:51,966 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 438
2023-02-20T09:53:51,966 [INFO ] W-9000-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51117 "PUT /predictions/helmet_detection HTTP/1.1" 200 439
2023-02-20T09:53:51,966 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:53:51,966 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 69823, Backend time ns: 439419374
2023-02-20T09:53:51,966 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 69823, Backend time ns: 439419374
2023-02-20T09:53:51,966 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858031
2023-02-20T09:53:51,967 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858031
2023-02-20T09:54:19,720 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858059
2023-02-20T09:54:19,720 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:630.3009414672852|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858059
2023-02-20T09:54:19,721 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858059
2023-02-20T09:54:19,721 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858059
2023-02-20T09:54:19,721 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:16841.1953125|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858059
2023-02-20T09:54:19,721 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:13843.6640625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858059
2023-02-20T09:54:19,721 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:48.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858059
2023-02-20T09:54:52,276 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858092276
2023-02-20T09:54:52,276 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858092276
2023-02-20T09:54:52,277 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858092
2023-02-20T09:54:52,695 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:417.07|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:d5a9c524-317e-46b7-bd70-ae0d3e166285,timestamp:1676858092
2023-02-20T09:54:52,695 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:417.79|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:d5a9c524-317e-46b7-bd70-ae0d3e166285,timestamp:1676858092
2023-02-20T09:54:52,695 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 418
2023-02-20T09:54:52,695 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 418
2023-02-20T09:54:52,696 [INFO ] W-9001-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51121 "PUT /predictions/helmet_detection HTTP/1.1" 200 421
2023-02-20T09:54:52,696 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:54:52,696 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 62031, Backend time ns: 420063274
2023-02-20T09:54:52,696 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 62031, Backend time ns: 420063274
2023-02-20T09:54:52,696 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858092
2023-02-20T09:54:52,696 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858092
2023-02-20T09:55:01,681 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858101681
2023-02-20T09:55:01,681 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858101681
2023-02-20T09:55:01,682 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858101
2023-02-20T09:55:03,220 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:1536.61|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:044dbc95-2126-470d-ae80-b074547e70d0,timestamp:1676858103
2023-02-20T09:55:03,220 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1536.96|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:044dbc95-2126-470d-ae80-b074547e70d0,timestamp:1676858103
2023-02-20T09:55:03,220 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1538
2023-02-20T09:55:03,220 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1538
2023-02-20T09:55:03,220 [INFO ] W-9002-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51126 "GET /predictions/helmet_detection HTTP/1.1" 200 1539
2023-02-20T09:55:03,220 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:55:03,220 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 73415, Backend time ns: 1539162874
2023-02-20T09:55:03,220 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 73415, Backend time ns: 1539162874
2023-02-20T09:55:03,220 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858103
2023-02-20T09:55:03,220 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858103
2023-02-20T09:55:11,267 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858111267
2023-02-20T09:55:11,267 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858111267
2023-02-20T09:55:11,267 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858111
2023-02-20T09:55:12,786 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:1518.44|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:4c1925ec-b1e5-4a21-9eb4-680b790d9b86,timestamp:1676858112
2023-02-20T09:55:12,787 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1518.8|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:4c1925ec-b1e5-4a21-9eb4-680b790d9b86,timestamp:1676858112
2023-02-20T09:55:12,787 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1520
2023-02-20T09:55:12,787 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1520
2023-02-20T09:55:12,787 [INFO ] W-9000-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51128 "GET /predictions/helmet_detection HTTP/1.1" 200 1520
2023-02-20T09:55:12,787 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:55:12,787 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 76564, Backend time ns: 1520487663
2023-02-20T09:55:12,787 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 76564, Backend time ns: 1520487663
2023-02-20T09:55:12,787 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858112
2023-02-20T09:55:12,787 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858112
2023-02-20T09:55:19,707 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858119
2023-02-20T09:55:19,707 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:630.3014831542969|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858119
2023-02-20T09:55:19,707 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858119
2023-02-20T09:55:19,707 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858119
2023-02-20T09:55:19,707 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:16577.53515625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858119
2023-02-20T09:55:19,707 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:14106.63671875|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858119
2023-02-20T09:55:19,708 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:49.4|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858119
2023-02-20T09:56:19,686 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858179
2023-02-20T09:56:19,686 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:630.299560546875|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858179
2023-02-20T09:56:19,686 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858179
2023-02-20T09:56:19,686 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858179
2023-02-20T09:56:19,686 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:16601.61328125|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858179
2023-02-20T09:56:19,686 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:14084.66796875|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858179
2023-02-20T09:56:19,687 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:49.3|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858179
2023-02-20T09:56:34,439 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858194439
2023-02-20T09:56:34,439 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858194439
2023-02-20T09:56:34,441 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858194
2023-02-20T09:56:35,932 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:1490.85|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:7e316f57-9074-453a-9aa8-153ce2f154db,timestamp:1676858195
2023-02-20T09:56:35,932 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1491.21|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:7e316f57-9074-453a-9aa8-153ce2f154db,timestamp:1676858195
2023-02-20T09:56:35,933 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1492
2023-02-20T09:56:35,933 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1492
2023-02-20T09:56:35,933 [INFO ] W-9001-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51138 "PUT /predictions/helmet_detection HTTP/1.1" 200 1495
2023-02-20T09:56:35,933 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:56:35,933 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 60143, Backend time ns: 1494292651
2023-02-20T09:56:35,933 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 60143, Backend time ns: 1494292651
2023-02-20T09:56:35,933 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858195
2023-02-20T09:56:35,933 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858195
2023-02-20T09:57:15,653 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858235653
2023-02-20T09:57:15,653 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858235653
2023-02-20T09:57:15,654 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858235
2023-02-20T09:57:15,915 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:260.65|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:e82a612a-70ae-49f2-b7ad-06d88a80e205,timestamp:1676858235
2023-02-20T09:57:15,915 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:261.0|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:e82a612a-70ae-49f2-b7ad-06d88a80e205,timestamp:1676858235
2023-02-20T09:57:15,915 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 261
2023-02-20T09:57:15,915 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 261
2023-02-20T09:57:15,915 [INFO ] W-9002-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51153 "PUT /predictions/helmet_detection HTTP/1.1" 200 263
2023-02-20T09:57:15,915 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:57:15,916 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 63547, Backend time ns: 262880381
2023-02-20T09:57:15,916 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 63547, Backend time ns: 262880381
2023-02-20T09:57:15,916 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858235
2023-02-20T09:57:15,916 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858235
2023-02-20T09:57:19,696 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858239
2023-02-20T09:57:19,696 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:630.3381576538086|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858239
2023-02-20T09:57:19,696 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858239
2023-02-20T09:57:19,696 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858239
2023-02-20T09:57:19,696 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:16546.91015625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858239
2023-02-20T09:57:19,697 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:14140.578125|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858239
2023-02-20T09:57:19,697 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:49.5|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858239
2023-02-20T09:58:19,691 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858299
2023-02-20T09:58:19,691 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:630.337459564209|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858299
2023-02-20T09:58:19,691 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858299
2023-02-20T09:58:19,692 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858299
2023-02-20T09:58:19,692 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:16447.55078125|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858299
2023-02-20T09:58:19,692 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:14240.4765625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858299
2023-02-20T09:58:19,692 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:49.8|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858299
2023-02-20T09:58:33,503 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858313503
2023-02-20T09:58:33,503 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858313503
2023-02-20T09:58:33,504 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858313
2023-02-20T09:58:33,771 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:266.95|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:d36cc191-a618-4e13-b631-cbaf536dad37,timestamp:1676858313
2023-02-20T09:58:33,772 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:267.82|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:d36cc191-a618-4e13-b631-cbaf536dad37,timestamp:1676858313
2023-02-20T09:58:33,772 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 268
2023-02-20T09:58:33,772 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 268
2023-02-20T09:58:33,773 [INFO ] W-9000-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51167 "POST /predictions/helmet_detection HTTP/1.1" 200 313
2023-02-20T09:58:33,773 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676857921
2023-02-20T09:58:33,773 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 117849, Backend time ns: 269865148
2023-02-20T09:58:33,773 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 117849, Backend time ns: 269865148
2023-02-20T09:58:33,773 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858313
2023-02-20T09:58:33,773 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858313
2023-02-20T09:59:37,125 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-02-20T09:59:37,125 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-02-20T09:59:37,162 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-02-20T09:59:37,162 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-02-20T09:59:37,464 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages
Current directory: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources
Temp directory: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/
Metrics config path: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8192 M
Python executable: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python
Config file: logs/config/20230220095914246-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/model_store
Initial Models: helmet_detection.mar
Log dir: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/logs
Metrics dir: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/model_store
Model config: N/A
2023-02-20T09:59:37,464 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages
Current directory: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources
Temp directory: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/
Metrics config path: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 8192 M
Python executable: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python
Config file: logs/config/20230220095914246-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/model_store
Initial Models: helmet_detection.mar
Log dir: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/logs
Metrics dir: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/helmet_yolov5_torchserve/ressources/model_store
Model config: N/A
2023-02-20T09:59:37,471 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230220095914246-shutdown.cfg",
  "modelCount": 1,
  "created": 1676858354246,
  "models": {
    "helmet_detection": {
      "0.1": {
        "defaultVersion": true,
        "marName": "helmet_detection.mar",
        "minWorkers": 3,
        "maxWorkers": 3,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2023-02-20T09:59:37,471 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230220095914246-shutdown.cfg",
  "modelCount": 1,
  "created": 1676858354246,
  "models": {
    "helmet_detection": {
      "0.1": {
        "defaultVersion": true,
        "marName": "helmet_detection.mar",
        "minWorkers": 3,
        "maxWorkers": 3,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2023-02-20T09:59:37,478 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230220095914246-shutdown.cfg
2023-02-20T09:59:37,478 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230220095914246-shutdown.cfg
2023-02-20T09:59:37,478 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230220095914246-shutdown.cfg validated successfully
2023-02-20T09:59:37,478 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230220095914246-shutdown.cfg validated successfully
2023-02-20T09:59:38,139 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model helmet_detection
2023-02-20T09:59:38,139 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model helmet_detection
2023-02-20T09:59:38,140 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model helmet_detection
2023-02-20T09:59:38,140 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model helmet_detection
2023-02-20T09:59:38,140 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model helmet_detection
2023-02-20T09:59:38,140 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model helmet_detection
2023-02-20T09:59:38,140 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-02-20T09:59:38,140 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model helmet_detection loaded.
2023-02-20T09:59:38,140 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 3
2023-02-20T09:59:38,140 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: helmet_detection, count: 3
2023-02-20T09:59:38,152 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:59:38,152 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:59:38,152 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:59:38,152 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:59:38,152 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:59:38,152 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/bin/python, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001, --metrics-config, /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-02-20T09:59:38,154 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2023-02-20T09:59:38,154 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2023-02-20T09:59:38,233 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-02-20T09:59:38,233 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-02-20T09:59:38,234 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2023-02-20T09:59:38,234 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2023-02-20T09:59:38,235 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-02-20T09:59:38,235 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-02-20T09:59:38,235 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2023-02-20T09:59:38,235 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2023-02-20T09:59:38,236 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-02-20T09:59:38,236 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-02-20T09:59:38,466 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-02-20T09:59:38,466 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-02-20T09:59:38,570 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:60.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858378
2023-02-20T09:59:38,570 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:630.332145690918|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858378
2023-02-20T09:59:38,571 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858378
2023-02-20T09:59:38,571 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858378
2023-02-20T09:59:38,571 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17655.4765625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858378
2023-02-20T09:59:38,571 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13031.546875|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858378
2023-02-20T09:59:38,571 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858378
2023-02-20T09:59:39,490 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001
2023-02-20T09:59:39,490 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002
2023-02-20T09:59:39,493 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Listening on port: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000
2023-02-20T09:59:39,496 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:59:39,496 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:59:39,496 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - [PID]96855
2023-02-20T09:59:39,496 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - [PID]96854
2023-02-20T09:59:39,496 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:59:39,497 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:59:39,497 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:59:39,497 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:59:39,497 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:59:39,497 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:59:39,497 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:59:39,497 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:59:39,499 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Successfully loaded /Users/juanl/Documents/01-career/001-peachproject/04-model_matching/tutorial-examples/torch-env/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-02-20T09:59:39,499 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - [PID]96853
2023-02-20T09:59:39,499 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Torch worker started.
2023-02-20T09:59:39,499 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:59:39,499 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_0.1 State change null -> WORKER_STARTED
2023-02-20T09:59:39,499 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Python runtime: 3.8.9
2023-02-20T09:59:39,501 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000
2023-02-20T09:59:39,501 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002
2023-02-20T09:59:39,501 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001
2023-02-20T09:59:39,501 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000
2023-02-20T09:59:39,501 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002
2023-02-20T09:59:39,501 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001
2023-02-20T09:59:39,510 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9001.
2023-02-20T09:59:39,510 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9000.
2023-02-20T09:59:39,510 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Connection accepted: /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T//.ts.sock.9002.
2023-02-20T09:59:39,513 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858379513
2023-02-20T09:59:39,513 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858379513
2023-02-20T09:59:39,513 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858379513
2023-02-20T09:59:39,513 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858379513
2023-02-20T09:59:39,513 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858379513
2023-02-20T09:59:39,513 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858379513
2023-02-20T09:59:39,544 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:59:39,544 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:59:39,544 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - model_name: helmet_detection, batchSize: 1
2023-02-20T09:59:40,165 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/27bf5c72638443b3a7bc7d987f46caaf/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:59:40,165 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/27bf5c72638443b3a7bc7d987f46caaf/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:59:40,165 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:59:40,165 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:59:40,165 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - /var/folders/cm/pzskfkq17lq6vp0d73nrg1dw0000gq/T/models/27bf5c72638443b3a7bc7d987f46caaf/compile.json is missing. PT 2.0 will not be used
2023-02-20T09:59:40,166 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:59:40,166 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:59:40,166 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:59:40,166 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - dynamo/inductor are not installed. 
2023-02-20T09:59:40,166 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:59:40,166 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG -  For GPU please run pip3 install numpy --pre torch[dynamo] --force-reinstall --extra-index-url https://download.pytorch.org/whl/nightly/cu117 
2023-02-20T09:59:40,166 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG -  for CPU please run pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu
2023-02-20T09:59:40,171 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 627
2023-02-20T09:59:40,171 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 627
2023-02-20T09:59:40,171 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 627
2023-02-20T09:59:40,171 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 627
2023-02-20T09:59:40,171 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 627
2023-02-20T09:59:40,171 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 627
2023-02-20T09:59:40,171 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:59:40,171 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:59:40,172 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:59:40,171 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:59:40,171 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9000-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:59:40,172 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - W-9002-helmet_detection_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-02-20T09:59:40,172 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - W-9001-helmet_detection_0.1.ms:2023|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858380
2023-02-20T09:59:40,172 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - W-9000-helmet_detection_0.1.ms:2025|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858380
2023-02-20T09:59:40,172 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - W-9002-helmet_detection_0.1.ms:2023|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858380
2023-02-20T09:59:40,172 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:32|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858380
2023-02-20T09:59:40,173 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:32|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858380
2023-02-20T09:59:40,173 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:33|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858380
2023-02-20T10:00:38,555 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858438
2023-02-20T10:00:38,556 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:630.3321685791016|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858438
2023-02-20T10:00:38,556 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858438
2023-02-20T10:00:38,556 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858438
2023-02-20T10:00:38,557 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17237.265625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858438
2023-02-20T10:00:38,557 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13449.4453125|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858438
2023-02-20T10:00:38,557 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:47.4|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858438
2023-02-20T10:01:20,487 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858480487
2023-02-20T10:01:20,487 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858480487
2023-02-20T10:01:20,489 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858480
2023-02-20T10:01:20,920 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:429.61|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:7391c415-507c-4803-9e1a-25e3ec060774,timestamp:1676858480
2023-02-20T10:01:20,920 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:430.68|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:7391c415-507c-4803-9e1a-25e3ec060774,timestamp:1676858480
2023-02-20T10:01:20,921 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 432
2023-02-20T10:01:20,921 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 432
2023-02-20T10:01:20,922 [INFO ] W-9001-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51184 "PUT /predictions/helmet_detection HTTP/1.1" 200 441
2023-02-20T10:01:20,923 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858480
2023-02-20T10:01:20,923 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 134178, Backend time ns: 436222190
2023-02-20T10:01:20,923 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 134178, Backend time ns: 436222190
2023-02-20T10:01:20,923 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858480
2023-02-20T10:01:20,923 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858480
2023-02-20T10:01:30,872 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858490872
2023-02-20T10:01:30,872 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858490872
2023-02-20T10:01:30,873 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858490
2023-02-20T10:01:31,340 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:467.01|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:ab4953d9-b982-4849-a0e5-69ea6b95a94a,timestamp:1676858491
2023-02-20T10:01:31,341 [INFO ] W-9000-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:468.1|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:ab4953d9-b982-4849-a0e5-69ea6b95a94a,timestamp:1676858491
2023-02-20T10:01:31,341 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 469
2023-02-20T10:01:31,341 [INFO ] W-9000-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 469
2023-02-20T10:01:31,341 [INFO ] W-9000-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51187 "GET /predictions/helmet_detection HTTP/1.1" 200 470
2023-02-20T10:01:31,341 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858480
2023-02-20T10:01:31,342 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 95403, Backend time ns: 470026272
2023-02-20T10:01:31,342 [DEBUG] W-9000-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 95403, Backend time ns: 470026272
2023-02-20T10:01:31,342 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858491
2023-02-20T10:01:31,342 [INFO ] W-9000-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858491
2023-02-20T10:01:38,550 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858498
2023-02-20T10:01:38,550 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:630.3288269042969|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858498
2023-02-20T10:01:38,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858498
2023-02-20T10:01:38,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858498
2023-02-20T10:01:38,551 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:16992.171875|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858498
2023-02-20T10:01:38,551 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13699.5234375|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858498
2023-02-20T10:01:38,552 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:48.1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858498
2023-02-20T10:02:00,608 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858520608
2023-02-20T10:02:00,608 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858520608
2023-02-20T10:02:00,609 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858520
2023-02-20T10:02:01,065 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:455.45|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:dd7d4950-bf3c-4e52-89f0-a9b16c05ea14,timestamp:1676858521
2023-02-20T10:02:01,065 [INFO ] W-9002-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:455.88|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:dd7d4950-bf3c-4e52-89f0-a9b16c05ea14,timestamp:1676858521
2023-02-20T10:02:01,065 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 456
2023-02-20T10:02:01,065 [INFO ] W-9002-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 456
2023-02-20T10:02:01,066 [INFO ] W-9002-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51187 "GET /predictions/helmet_detection HTTP/1.1" 200 459
2023-02-20T10:02:01,066 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858480
2023-02-20T10:02:01,066 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 94227, Backend time ns: 458181124
2023-02-20T10:02:01,066 [DEBUG] W-9002-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 94227, Backend time ns: 458181124
2023-02-20T10:02:01,066 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858521
2023-02-20T10:02:01,066 [INFO ] W-9002-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858521
2023-02-20T10:02:38,557 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858558
2023-02-20T10:02:38,557 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:630.3374214172363|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858558
2023-02-20T10:02:38,558 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858558
2023-02-20T10:02:38,558 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858558
2023-02-20T10:02:38,558 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:16899.8046875|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858558
2023-02-20T10:02:38,558 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13795.21484375|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858558
2023-02-20T10:02:38,558 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:48.4|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858558
2023-02-20T10:03:01,149 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858581149
2023-02-20T10:03:01,149 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1676858581149
2023-02-20T10:03:01,151 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_LOG - Backend received inference at: 1676858581
2023-02-20T10:03:02,780 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:1628.45|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:bd094645-b5f7-42df-bbc8-f27d3c735709,timestamp:1676858582
2023-02-20T10:03:02,780 [INFO ] W-9001-helmet_detection_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.81|#ModelName:helmet_detection,Level:Model|#hostname:juanlEMD6R.vmware.com,requestID:bd094645-b5f7-42df-bbc8-f27d3c735709,timestamp:1676858582
2023-02-20T10:03:02,780 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629
2023-02-20T10:03:02,780 [INFO ] W-9001-helmet_detection_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629
2023-02-20T10:03:02,780 [INFO ] W-9001-helmet_detection_0.1 ACCESS_LOG - /127.0.0.1:51196 "POST /predictions/helmet_detection HTTP/1.1" 200 1632
2023-02-20T10:03:02,780 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858480
2023-02-20T10:03:02,780 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 55047, Backend time ns: 1631833167
2023-02-20T10:03:02,780 [DEBUG] W-9001-helmet_detection_0.1 org.pytorch.serve.job.Job - Waiting time ns: 55047, Backend time ns: 1631833167
2023-02-20T10:03:02,780 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858582
2023-02-20T10:03:02,781 [INFO ] W-9001-helmet_detection_0.1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858582
2023-02-20T10:03:38,551 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858618
2023-02-20T10:03:38,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:630.3336563110352|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858618
2023-02-20T10:03:38,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858618
2023-02-20T10:03:38,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858618
2023-02-20T10:03:38,551 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:16858.453125|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858618
2023-02-20T10:03:38,551 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13837.9375|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858618
2023-02-20T10:03:38,551 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:48.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858618
2023-02-20T10:04:38,559 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858678
2023-02-20T10:04:38,559 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:630.3336067199707|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858678
2023-02-20T10:04:38,559 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858678
2023-02-20T10:04:38,559 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858678
2023-02-20T10:04:38,560 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:16853.64453125|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858678
2023-02-20T10:04:38,560 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13842.37890625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858678
2023-02-20T10:04:38,560 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:48.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858678
2023-02-20T10:05:38,552 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858738
2023-02-20T10:05:38,552 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:630.3467903137207|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858738
2023-02-20T10:05:38,552 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.694202423095703|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858738
2023-02-20T10:05:38,552 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:3.6|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858738
2023-02-20T10:05:38,552 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:16781.3828125|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858738
2023-02-20T10:05:38,552 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13909.12890625|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858738
2023-02-20T10:05:38,552 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:48.8|#Level:Host|#hostname:juanlEMD6R.vmware.com,timestamp:1676858738
